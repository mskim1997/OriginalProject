
>>> Values:
 Random Seed Value = 40736
 Number of Physical Paths = 20
 Number of Learning Paths per Physical Path = 1
 Method = 5
 Number of Lookahead Levels = 1
 Path-File Mode = 3
 Step-Size Parameter ALPHA = 0.100000
 Discount Rate GAMMA = 0.900000
 Lookahead Weight Factor LAMBDA = 0.500000
 Q-value Weight Factor w1 = 0.800000
 Distance-to-Goal Weight Factor w2 = 0.500000
 Initial Full Exploration is OFF
 Visited-Number Weight factor w3 = 0.500000
 TAW has greedy-mode value = 1
 Star is 3 at location [6, 0]
 Goal is W

>>> Input Maze:
 O  O  O  O  O  O  O  B 
 O  O  O  O  B  O  O  O 
 O  O  O  B  O  O  O  O 
 O  B  O  O  O  B  O  O 
 O  B  O  B  O  B  O  O 
 O  O  O  O  O  O  O  B 
 O  O  O  O  O  O  B  B 
 B  O  O  O  B  O  B  J 
 O  O  O  B  O  O  O  O 
 O  B  O  O  O  B  O  B 
 O  B  O  B  O  B  O  X 
 O  E  O  W  O  O  H  B 


>>> Agent Physical Path 1:

>>> Physical path 1, Time: 0.030000 s, Min radius: 9.469607 Total Steps: 386.
 Step   1: Agent moved  DOWN to location [x=6,y=1], randomly.
 Step   2: Agent moved RIGHT to location [x=7,y=1], randomly.
 Step   3: Agent moved DOWN_LEFT to location [x=6,y=2], randomly.
 Step   4: Agent moved  DOWN to location [x=6,y=3], randomly.
 Step   5: Agent moved DOWN_RIGHT to location [x=7,y=4], randomly.
 Step   6: Agent moved DOWN_LEFT to location [x=6,y=5], randomly.
 Step   7: Agent moved    UP to location [x=6,y=4], randomly.
 Step   8: Agent moved  DOWN to location [x=6,y=5], randomly.
 Step   9: Agent moved  LEFT to location [x=5,y=5], randomly.
 Step  10: Agent moved RIGHT to location [x=6,y=5], randomly.
 Step  11: Agent moved    UP to location [x=6,y=4], randomly.
 Step  12: Agent moved    UP to location [x=6,y=3], randomly.
 Step  13: Agent moved UP_RIGHT to location [x=7,y=2], randomly.
 Step  14: Agent moved DOWN_LEFT to location [x=6,y=3], randomly.
 Step  15: Agent moved    UP to location [x=6,y=2], randomly.
 Step  16: Agent moved  DOWN to location [x=6,y=3], randomly.
 Step  17: Agent moved  DOWN to location [x=6,y=4], randomly.
 Step  18: Agent moved  DOWN to location [x=6,y=5], randomly.
 Step  19: Agent moved  LEFT to location [x=5,y=5], randomly.
 Step  20: Agent moved DOWN_LEFT to location [x=4,y=6], randomly.
 Step  21: Agent moved    UP to location [x=4,y=5], randomly.
 Step  22: Agent moved DOWN_LEFT to location [x=3,y=6], randomly.
 Step  23: Agent moved  DOWN to location [x=3,y=7], randomly.
 Step  24: Agent moved    UP to location [x=3,y=6], randomly.
 Step  25: Agent moved  LEFT to location [x=2,y=6], randomly.
 Step  26: Agent moved UP_RIGHT to location [x=3,y=5], randomly.
 Step  27: Agent moved RIGHT to location [x=4,y=5], randomly.
 Step  28: Agent moved DOWN_RIGHT to location [x=5,y=6], randomly.
 Step  29: Agent moved  DOWN to location [x=5,y=7], randomly.
 Step  30: Agent moved  DOWN to location [x=5,y=8], randomly.
 Step  31: Agent moved  LEFT to location [x=4,y=8], randomly.
 Step  32: Agent moved DOWN_LEFT to location [x=3,y=9], randomly.
 Step  33: Agent moved RIGHT to location [x=4,y=9], randomly.
 Step  34: Agent moved    UP to location [x=4,y=8], randomly.
 Step  35: Agent moved  DOWN to location [x=4,y=9], randomly.
 Step  36: Agent moved UP_RIGHT to location [x=5,y=8], randomly.
 Step  37: Agent moved DOWN_LEFT to location [x=4,y=9], randomly.
 Step  38: Agent moved  LEFT to location [x=3,y=9], randomly.
 Step  39: Agent moved RIGHT to location [x=4,y=9], randomly.
 Step  40: Agent moved  LEFT to location [x=3,y=9], randomly.
 Step  41: Agent moved UP_RIGHT to location [x=4,y=8], randomly.
 Step  42: Agent moved  DOWN to location [x=4,y=9], randomly.
 Step  43: Agent moved  DOWN to location [x=4,y=10], randomly.
 Step  44: Agent moved DOWN_RIGHT to location [x=5,y=11], randomly.
 Step  45: Agent moved  LEFT to location [x=4,y=11], randomly.
 Step  46: Agent moved    UP to location [x=4,y=10], randomly.
 Step  47: Agent moved  DOWN to location [x=4,y=11], randomly.
 Step  48: Agent moved  LEFT to location [x=3,y=11], randomly.

>>> Agent Brain:
 ?  ?  ?  ?  ?  ?  3  ? 
 ?  ?  ?  ?  ?  ?  O  O 
 ?  ?  ?  ?  ?  ?  O  O 
 ?  ?  ?  ?  ?  B  O  ? 
 ?  ?  ?  ?  ?  B  O  O 
 ?  ?  ?  O  O  O  O  B 
 ?  ?  O  O  O  O  ?  B 
 ?  ?  ?  O  B  O  ?  ? 
 ?  ?  ?  B  O  O  ?  ? 
 ?  ?  ?  O  O  B  ?  ? 
 ?  ?  ?  B  O  B  ?  ? 
 ?  ?  ?  W  O  O  ?  ? 


>>> Agent Physical Path 2:

>>> Physical path 2, Time: 0.120000 s, Min radius: 3.771236 Total Steps: 26.
 Step   1: Agent moved  DOWN to location [x=5,y=1], based on policy.
 Step   2: Agent moved  DOWN to location [x=5,y=2], based on policy.
 Step   3: Agent moved DOWN_LEFT to location [x=4,y=3], based on policy.
 Step   4: Agent moved  DOWN to location [x=4,y=4], based on policy.
 Step   5: Agent moved  DOWN to location [x=4,y=5], based on policy.
 Step   6: Agent moved  DOWN to location [x=4,y=6], based on policy.
 Step   7: Agent moved DOWN_LEFT to location [x=3,y=7], randomly.
 Step   8: Agent moved DOWN_LEFT to location [x=2,y=8], based on policy.
 Step   9: Agent moved  DOWN to location [x=2,y=9], based on policy.
 Step  10: Agent moved  DOWN to location [x=2,y=10], based on policy.
 Step  11: Agent moved DOWN_RIGHT to location [x=3,y=11], based on policy.

>>> Agent Brain:
 ?  ?  ?  ?  ?  3  ?  ? 
 ?  ?  ?  ?  ?  O  ?  ? 
 ?  ?  ?  ?  ?  O  ?  ? 
 ?  ?  ?  ?  O  B  ?  ? 
 ?  ?  ?  B  O  ?  ?  ? 
 ?  ?  ?  ?  O  ?  ?  ? 
 ?  ?  ?  ?  O  ?  ?  ? 
 ?  ?  ?  O  B  ?  ?  ? 
 ?  ?  O  ?  ?  ?  ?  ? 
 ?  ?  O  ?  ?  ?  ?  ? 
 ?  ?  O  ?  ?  ?  ?  ? 
 ?  ?  ?  W  ?  ?  ?  ? 


>>> Agent Physical Path 3:

>>> Physical path 3, Time: 0.034000 s, Min radius: 1.000000 Total Steps: 29.
 Step   1: Agent moved DOWN_RIGHT to location [x=2,y=1], based on policy.
 Step   2: Agent moved  DOWN to location [x=2,y=2], based on policy.
 Step   3: Agent moved  DOWN to location [x=2,y=3], based on policy.
 Step   4: Agent moved  DOWN to location [x=2,y=4], based on policy.
 Step   5: Agent moved  DOWN to location [x=2,y=5], based on policy.
 Step   6: Agent moved  DOWN to location [x=2,y=6], based on policy.
 Step   7: Agent moved  DOWN to location [x=2,y=7], based on policy.
 Step   8: Agent moved  DOWN to location [x=2,y=8], based on policy.
 Step   9: Agent moved  DOWN to location [x=2,y=9], based on policy.
 Step  10: Agent moved  DOWN to location [x=2,y=10], based on policy.
 Step  11: Agent moved DOWN_RIGHT to location [x=3,y=11], based on policy.

>>> Agent Brain:
 ?  3  ?  ?  ?  ?  ?  ? 
 ?  ?  O  ?  ?  ?  ?  ? 
 ?  ?  O  ?  ?  ?  ?  ? 
 ?  ?  O  ?  ?  B  ?  ? 
 ?  B  O  B  ?  ?  ?  ? 
 ?  ?  O  ?  ?  ?  ?  ? 
 ?  ?  O  ?  ?  ?  ?  ? 
 ?  ?  O  ?  B  ?  ?  ? 
 ?  ?  O  ?  ?  ?  ?  ? 
 ?  ?  O  ?  ?  ?  ?  ? 
 ?  ?  O  ?  ?  ?  ?  ? 
 ?  ?  ?  W  ?  ?  ?  ? 


>>> Agent Physical Path 4:

>>> Physical path 4, Time: 0.335000 s, Min radius: 3.771236 Total Steps: 65.
 Step   1: Agent moved  DOWN to location [x=5,y=1], based on policy.
 Step   2: Agent moved  DOWN to location [x=5,y=2], based on policy.
 Step   3: Agent moved DOWN_LEFT to location [x=4,y=3], based on policy.
 Step   4: Agent moved  DOWN to location [x=4,y=4], based on policy.
 Step   5: Agent moved DOWN_RIGHT to location [x=5,y=5], based on policy.
 Step   6: Agent moved  DOWN to location [x=5,y=6], based on policy.
 Step   7: Agent moved  DOWN to location [x=5,y=7], based on policy.
 Step   8: Agent moved DOWN_RIGHT to location [x=6,y=8], based on policy.
 Step   9: Agent moved  DOWN to location [x=6,y=9], based on policy.
 Step  10: Agent moved  DOWN to location [x=6,y=10], based on policy.
 Step  11: Agent moved  DOWN to location [x=6,y=11], based on policy.
 Step  12: Agent moved  LEFT to location [x=5,y=11], randomly.
 Step  13: Agent moved  LEFT to location [x=4,y=11], based on policy.
 Step  14: Agent moved  LEFT to location [x=3,y=11], based on policy.

>>> Agent Brain:
 ?  ?  ?  ?  ?  3  ?  ? 
 ?  ?  ?  ?  ?  O  ?  ? 
 ?  ?  ?  ?  ?  O  ?  ? 
 ?  ?  ?  ?  O  B  ?  ? 
 ?  B  ?  B  O  ?  ?  ? 
 ?  ?  ?  ?  ?  O  ?  ? 
 ?  ?  ?  ?  ?  O  ?  ? 
 ?  ?  ?  ?  B  O  ?  ? 
 ?  ?  ?  ?  ?  ?  O  ? 
 ?  ?  ?  ?  ?  ?  O  ? 
 ?  ?  ?  ?  ?  B  O  ? 
 ?  ?  ?  W  O  O  H  B 


>>> Agent Physical Path 5:

>>> Physical path 5, Time: 0.070000 s, Min radius: 3.771236 Total Steps: 30.
 Step   1: Agent moved  DOWN to location [x=5,y=1], based on policy.
 Step   2: Agent moved  DOWN to location [x=5,y=2], based on policy.
 Step   3: Agent moved DOWN_LEFT to location [x=4,y=3], based on policy.
 Step   4: Agent moved  DOWN to location [x=4,y=4], based on policy.
 Step   5: Agent moved DOWN_RIGHT to location [x=5,y=5], based on policy.
 Step   6: Agent moved  DOWN to location [x=5,y=6], based on policy.
 Step   7: Agent moved  DOWN to location [x=5,y=7], based on policy.
 Step   8: Agent moved DOWN_RIGHT to location [x=6,y=8], based on policy.
 Step   9: Agent moved  DOWN to location [x=6,y=9], based on policy.
 Step  10: Agent moved  DOWN to location [x=6,y=10], based on policy.
 Step  11: Agent moved  DOWN to location [x=6,y=11], based on policy.
 Step  12: Agent moved  LEFT to location [x=5,y=11], randomly.
 Step  13: Agent moved  LEFT to location [x=4,y=11], based on policy.
 Step  14: Agent moved  LEFT to location [x=3,y=11], based on policy.

>>> Agent Brain:
 ?  ?  ?  ?  ?  3  ?  ? 
 ?  ?  ?  ?  ?  O  ?  ? 
 ?  ?  ?  ?  ?  O  ?  ? 
 ?  ?  ?  ?  O  B  ?  ? 
 ?  B  ?  B  O  ?  ?  ? 
 ?  ?  ?  ?  ?  O  ?  ? 
 ?  ?  ?  ?  ?  O  ?  ? 
 ?  ?  ?  ?  B  O  ?  ? 
 ?  ?  ?  ?  ?  ?  O  ? 
 ?  ?  ?  ?  ?  ?  O  ? 
 ?  ?  ?  ?  ?  B  O  ? 
 ?  ?  ?  W  O  O  H  B 


>>> Agent Physical Path 6:

>>> Physical path 6, Time: 0.063000 s, Min radius: 9.000000 Total Steps: 27.
 Step   1: Agent moved  DOWN to location [x=2,y=1], based on policy.
 Step   2: Agent moved  DOWN to location [x=2,y=2], based on policy.
 Step   3: Agent moved  DOWN to location [x=2,y=3], based on policy.
 Step   4: Agent moved  DOWN to location [x=2,y=4], based on policy.
 Step   5: Agent moved  DOWN to location [x=2,y=5], based on policy.
 Step   6: Agent moved  DOWN to location [x=2,y=6], based on policy.
 Step   7: Agent moved  DOWN to location [x=2,y=7], based on policy.
 Step   8: Agent moved  DOWN to location [x=2,y=8], based on policy.
 Step   9: Agent moved  DOWN to location [x=2,y=9], based on policy.
 Step  10: Agent moved  DOWN to location [x=2,y=10], based on policy.
 Step  11: Agent moved DOWN_RIGHT to location [x=3,y=11], based on policy.

>>> Agent Brain:
 ?  ?  3  ?  ?  ?  ?  ? 
 ?  ?  O  ?  ?  ?  ?  ? 
 ?  ?  O  ?  ?  ?  ?  ? 
 ?  ?  O  ?  ?  B  ?  ? 
 ?  B  O  B  ?  ?  ?  ? 
 ?  ?  O  ?  ?  ?  ?  ? 
 ?  ?  O  ?  ?  ?  ?  ? 
 ?  ?  O  ?  B  ?  ?  ? 
 ?  ?  O  ?  ?  ?  ?  ? 
 ?  ?  O  ?  ?  ?  ?  ? 
 ?  ?  O  ?  ?  B  ?  ? 
 ?  ?  ?  W  ?  ?  ?  B 


>>> Agent Physical Path 7:

>>> Physical path 7, Time: 0.851000 s, Min radius: 0.500000 Total Steps: 69.
 Step   1: Agent moved  DOWN to location [x=3,y=1], based on policy.
 Step   2: Agent moved DOWN_RIGHT to location [x=4,y=2], based on policy.
 Step   3: Agent moved RIGHT to location [x=5,y=2], based on policy.
 Step   4: Agent moved UP_RIGHT to location [x=6,y=1], based on policy.
 Step   5: Agent moved RIGHT to location [x=7,y=1], based on policy.
 Step   6: Agent moved  DOWN to location [x=7,y=2], randomly.
 Step   7: Agent moved  DOWN to location [x=7,y=3], based on policy.
 Step   8: Agent moved  DOWN to location [x=7,y=4], based on policy.
 Step   9: Agent moved DOWN_LEFT to location [x=6,y=5], based on policy.
 Step  10: Agent moved DOWN_LEFT to location [x=5,y=6], based on policy.
 Step  11: Agent moved  DOWN to location [x=5,y=7], based on policy.
 Step  12: Agent moved  DOWN to location [x=5,y=8], based on policy.
 Step  13: Agent moved DOWN_LEFT to location [x=4,y=9], based on policy.
 Step  14: Agent moved  LEFT to location [x=3,y=9], based on policy.
 Step  15: Agent moved  LEFT to location [x=2,y=9], based on policy.
 Step  16: Agent moved    UP to location [x=2,y=8], randomly.
 Step  17: Agent moved UP_LEFT to location [x=1,y=7], based on policy.
 Step  18: Agent moved    UP to location [x=1,y=6], based on policy.
 Step  19: Agent moved UP_RIGHT to location [x=2,y=5], based on policy.
 Step  20: Agent moved RIGHT to location [x=3,y=5], based on policy.
 Step  21: Agent moved DOWN_RIGHT to location [x=4,y=6], based on policy.
 Step  22: Agent moved DOWN_RIGHT to location [x=5,y=7], based on policy.
 Step  23: Agent moved DOWN_RIGHT to location [x=6,y=8], based on policy.
 Step  24: Agent moved  DOWN to location [x=6,y=9], based on policy.
 Step  25: Agent moved DOWN_RIGHT to location [x=7,y=10], randomly.
 Step  26: Agent moved  LEFT to location [x=6,y=10], randomly.
 Step  27: Agent moved DOWN_LEFT to location [x=5,y=11], based on policy.
 Step  28: Agent moved UP_LEFT to location [x=4,y=10], randomly.
 Step  29: Agent moved UP_LEFT to location [x=3,y=9], based on policy.
 Step  30: Agent moved UP_LEFT to location [x=2,y=8], based on policy.
 Step  31: Agent moved    UP to location [x=2,y=7], based on policy.
 Step  32: Agent moved UP_LEFT to location [x=1,y=6], based on policy.
 Step  33: Agent moved    UP to location [x=1,y=5], based on policy.
 Step  34: Agent moved UP_LEFT to location [x=0,y=4], based on policy.
 Step  35: Agent moved  DOWN to location [x=0,y=5], randomly.
 Step  36: Agent moved  DOWN to location [x=0,y=6], based on policy.
 Step  37: Agent moved DOWN_RIGHT to location [x=1,y=7], based on policy.
 Step  38: Agent moved DOWN_RIGHT to location [x=2,y=8], based on policy.
 Step  39: Agent moved DOWN_RIGHT to location [x=3,y=9], based on policy.
 Step  40: Agent moved DOWN_RIGHT to location [x=4,y=10], based on policy.
 Step  41: Agent moved DOWN_RIGHT to location [x=5,y=11], based on policy.
 Step  42: Agent moved UP_LEFT to location [x=4,y=10], randomly.
 Step  43: Agent moved UP_LEFT to location [x=3,y=9], based on policy.
 Step  44: Agent moved UP_LEFT to location [x=2,y=8], based on policy.
 Step  45: Agent moved    UP to location [x=2,y=7], based on policy.
 Step  46: Agent moved UP_LEFT to location [x=1,y=6], based on policy.
 Step  47: Agent moved    UP to location [x=1,y=5], based on policy.
 Step  48: Agent moved UP_LEFT to location [x=0,y=4], based on policy.
 Step  49: Agent moved DOWN_RIGHT to location [x=1,y=5], randomly.
 Step  50: Agent moved  DOWN to location [x=1,y=6], based on policy.
 Step  51: Agent moved  DOWN to location [x=1,y=7], based on policy.
 Step  52: Agent moved DOWN_RIGHT to location [x=2,y=8], based on policy.
 Step  53: Agent moved  DOWN to location [x=2,y=9], based on policy.
 Step  54: Agent moved  DOWN to location [x=2,y=10], based on policy.
 Step  55: Agent moved  DOWN to location [x=2,y=11], based on policy.
 Step  56: Agent moved RIGHT to location [x=3,y=11], randomly.

>>> Agent Brain:
 ?  ?  ?  3  ?  ?  ?  ? 
 ?  ?  ?  O  ?  ?  O  O 
 ?  ?  ?  B  O  O  ?  O 
 ?  ?  ?  ?  ?  B  ?  O 
 O  B  ?  B  ?  ?  ?  O 
 O  O  O  O  ?  ?  O  B 
 O  O  ?  ?  O  O  ?  ? 
 B  O  O  ?  B  O  ?  ? 
 ?  ?  O  ?  ?  O  O  ? 
 ?  B  O  O  O  B  O  B 
 ?  ?  O  B  O  B  O  X 
 ?  ?  O  W  ?  O  ?  B 


>>> Agent Physical Path 8:

>>> Physical path 8, Time: 0.084000 s, Min radius: 6.324555 Total Steps: 32.
 Step   1: Agent moved  DOWN to location [x=1,y=1], based on policy.
 Step   2: Agent moved  DOWN to location [x=1,y=2], based on policy.
 Step   3: Agent moved DOWN_LEFT to location [x=0,y=3], based on policy.
 Step   4: Agent moved  DOWN to location [x=0,y=4], based on policy.
 Step   5: Agent moved  DOWN to location [x=0,y=5], based on policy.
 Step   6: Agent moved  DOWN to location [x=0,y=6], based on policy.
 Step   7: Agent moved DOWN_RIGHT to location [x=1,y=7], based on policy.
 Step   8: Agent moved DOWN_RIGHT to location [x=2,y=8], based on policy.
 Step   9: Agent moved DOWN_RIGHT to location [x=3,y=9], based on policy.
 Step  10: Agent moved DOWN_RIGHT to location [x=4,y=10], based on policy.
 Step  11: Agent moved DOWN_RIGHT to location [x=5,y=11], based on policy.
 Step  12: Agent moved  LEFT to location [x=4,y=11], randomly.
 Step  13: Agent moved  LEFT to location [x=3,y=11], based on policy.

>>> Agent Brain:
 ?  3  ?  ?  ?  ?  ?  ? 
 ?  O  ?  ?  ?  ?  ?  ? 
 ?  O  ?  B  ?  ?  ?  ? 
 O  ?  ?  ?  ?  B  ?  ? 
 O  B  ?  B  ?  ?  ?  ? 
 O  ?  ?  ?  ?  ?  ?  B 
 O  ?  ?  ?  ?  ?  ?  ? 
 B  O  ?  ?  B  ?  ?  ? 
 ?  ?  O  ?  ?  ?  ?  ? 
 ?  B  ?  O  ?  B  ?  B 
 ?  ?  ?  B  O  B  ?  ? 
 ?  ?  ?  W  O  O  ?  B 


>>> Agent Physical Path 9:

>>> Physical path 9, Time: 0.737000 s, Min radius: 2.795085 Total Steps: 44.
 Step   1: Agent moved  DOWN to location [x=6,y=1], based on policy.
 Step   2: Agent moved  DOWN to location [x=6,y=2], based on policy.
 Step   3: Agent moved DOWN_RIGHT to location [x=7,y=3], based on policy.
 Step   4: Agent moved  DOWN to location [x=7,y=4], based on policy.
 Step   5: Agent moved DOWN_LEFT to location [x=6,y=5], based on policy.
 Step   6: Agent moved DOWN_LEFT to location [x=5,y=6], based on policy.
 Step   7: Agent moved  DOWN to location [x=5,y=7], based on policy.
 Step   8: Agent moved DOWN_RIGHT to location [x=6,y=8], based on policy.
 Step   9: Agent moved  DOWN to location [x=6,y=9], based on policy.
 Step  10: Agent moved  DOWN to location [x=6,y=10], based on policy.
 Step  11: Agent moved  DOWN to location [x=6,y=11], based on policy.
 Step  12: Agent moved UP_RIGHT to location [x=7,y=10], randomly.
 Step  13: Agent moved  LEFT to location [x=6,y=10], randomly.
 Step  14: Agent moved DOWN_LEFT to location [x=5,y=11], based on policy.
 Step  15: Agent moved UP_LEFT to location [x=4,y=10], randomly.
 Step  16: Agent moved UP_LEFT to location [x=3,y=9], based on policy.
 Step  17: Agent moved UP_LEFT to location [x=2,y=8], based on policy.
 Step  18: Agent moved    UP to location [x=2,y=7], based on policy.
 Step  19: Agent moved UP_LEFT to location [x=1,y=6], based on policy.
 Step  20: Agent moved    UP to location [x=1,y=5], based on policy.
 Step  21: Agent moved UP_LEFT to location [x=0,y=4], based on policy.
 Step  22: Agent moved DOWN_RIGHT to location [x=1,y=5], randomly.
 Step  23: Agent moved  DOWN to location [x=1,y=6], based on policy.
 Step  24: Agent moved  DOWN to location [x=1,y=7], based on policy.
 Step  25: Agent moved DOWN_RIGHT to location [x=2,y=8], based on policy.
 Step  26: Agent moved  DOWN to location [x=2,y=9], based on policy.
 Step  27: Agent moved  DOWN to location [x=2,y=10], based on policy.
 Step  28: Agent moved  DOWN to location [x=2,y=11], based on policy.
 Step  29: Agent moved  LEFT to location [x=1,y=11], randomly.
 Step  30: Agent moved  LEFT to location [x=0,y=11], based on policy.
 Step  31: Agent moved RIGHT to location [x=1,y=11], randomly.
 Step  32: Agent moved RIGHT to location [x=2,y=11], based on policy.
 Step  33: Agent moved RIGHT to location [x=3,y=11], based on policy.

>>> Agent Brain:
 ?  ?  ?  ?  ?  ?  3  ? 
 ?  ?  ?  ?  ?  ?  O  ? 
 ?  ?  ?  B  ?  ?  O  ? 
 ?  ?  ?  ?  ?  B  ?  O 
 O  B  ?  B  ?  ?  ?  O 
 ?  O  ?  ?  ?  ?  O  B 
 ?  O  ?  ?  ?  O  ?  ? 
 B  O  O  ?  B  O  ?  ? 
 ?  ?  O  ?  ?  ?  O  ? 
 ?  B  O  O  ?  B  O  B 
 ?  ?  O  B  O  B  O  X 
 O  E  O  W  ?  O  H  B 


>>> Agent Physical Path 10:

>>> Physical path 10, Time: 0.248000 s, Min radius: 0.500000 Total Steps: 42.
 Step   1: Agent moved  DOWN to location [x=2,y=1], based on policy.
 Step   2: Agent moved DOWN_LEFT to location [x=1,y=2], based on policy.
 Step   3: Agent moved  LEFT to location [x=0,y=2], based on policy.
 Step   4: Agent moved    UP to location [x=0,y=1], randomly.
 Step   5: Agent moved UP_RIGHT to location [x=1,y=0], based on policy.
 Step   6: Agent moved RIGHT to location [x=2,y=0], based on policy.
 Step   7: Agent moved DOWN_RIGHT to location [x=3,y=1], based on policy.
 Step   8: Agent moved DOWN_LEFT to location [x=2,y=2], randomly.
 Step   9: Agent moved  LEFT to location [x=1,y=2], based on policy.
 Step  10: Agent moved UP_LEFT to location [x=0,y=1], based on policy.
 Step  11: Agent moved RIGHT to location [x=1,y=1], randomly.
 Step  12: Agent moved DOWN_RIGHT to location [x=2,y=2], based on policy.
 Step  13: Agent moved  DOWN to location [x=2,y=3], based on policy.
 Step  14: Agent moved  DOWN to location [x=2,y=4], based on policy.
 Step  15: Agent moved  DOWN to location [x=2,y=5], based on policy.
 Step  16: Agent moved  DOWN to location [x=2,y=6], based on policy.
 Step  17: Agent moved  DOWN to location [x=2,y=7], based on policy.
 Step  18: Agent moved  DOWN to location [x=2,y=8], based on policy.
 Step  19: Agent moved DOWN_RIGHT to location [x=3,y=9], based on policy.
 Step  20: Agent moved DOWN_RIGHT to location [x=4,y=10], based on policy.
 Step  21: Agent moved DOWN_RIGHT to location [x=5,y=11], based on policy.
 Step  22: Agent moved RIGHT to location [x=6,y=11], randomly.
 Step  23: Agent moved  LEFT to location [x=5,y=11], randomly.
 Step  24: Agent moved  LEFT to location [x=4,y=11], based on policy.
 Step  25: Agent moved  LEFT to location [x=3,y=11], based on policy.

>>> Agent Brain:
 ?  O  O  ?  ?  ?  ?  ? 
 O  O  O  O  B  ?  ?  ? 
 O  O  O  B  ?  ?  ?  ? 
 ?  B  O  ?  ?  B  ?  ? 
 ?  B  O  B  ?  ?  ?  ? 
 ?  ?  O  ?  ?  ?  ?  B 
 ?  ?  O  ?  ?  ?  ?  ? 
 B  ?  O  ?  B  ?  ?  ? 
 ?  ?  O  ?  ?  ?  ?  ? 
 ?  B  ?  O  ?  B  ?  B 
 ?  ?  ?  B  O  B  ?  ? 
 ?  ?  ?  W  O  O  H  B 


>>> Agent Physical Path 11:

>>> Physical path 11, Time: 0.195000 s, Min radius: 0.500000 Total Steps: 41.
 Step   1: Agent moved  DOWN to location [x=3,y=1], based on policy.
 Step   2: Agent moved DOWN_LEFT to location [x=2,y=2], based on policy.
 Step   3: Agent moved  LEFT to location [x=1,y=2], based on policy.
 Step   4: Agent moved UP_LEFT to location [x=0,y=1], based on policy.
 Step   5: Agent moved RIGHT to location [x=1,y=1], randomly.
 Step   6: Agent moved DOWN_RIGHT to location [x=2,y=2], based on policy.
 Step   7: Agent moved  DOWN to location [x=2,y=3], based on policy.
 Step   8: Agent moved  DOWN to location [x=2,y=4], based on policy.
 Step   9: Agent moved  DOWN to location [x=2,y=5], based on policy.
 Step  10: Agent moved  DOWN to location [x=2,y=6], based on policy.
 Step  11: Agent moved  DOWN to location [x=2,y=7], based on policy.
 Step  12: Agent moved  DOWN to location [x=2,y=8], based on policy.
 Step  13: Agent moved DOWN_RIGHT to location [x=3,y=9], based on policy.
 Step  14: Agent moved DOWN_RIGHT to location [x=4,y=10], based on policy.
 Step  15: Agent moved DOWN_RIGHT to location [x=5,y=11], based on policy.
 Step  16: Agent moved UP_RIGHT to location [x=6,y=10], randomly.
 Step  17: Agent moved RIGHT to location [x=7,y=10], based on policy.
 Step  18: Agent moved UP_LEFT to location [x=6,y=9], randomly.
 Step  19: Agent moved UP_LEFT to location [x=5,y=8], based on policy.
 Step  20: Agent moved  LEFT to location [x=4,y=8], based on policy.
 Step  21: Agent moved DOWN_LEFT to location [x=3,y=9], based on policy.
 Step  22: Agent moved DOWN_LEFT to location [x=2,y=10], based on policy.
 Step  23: Agent moved  DOWN to location [x=2,y=11], based on policy.
 Step  24: Agent moved RIGHT to location [x=3,y=11], randomly.

>>> Agent Brain:
 ?  ?  ?  3  ?  ?  ?  ? 
 O  O  ?  O  B  ?  ?  ? 
 ?  O  O  B  ?  ?  ?  ? 
 ?  B  O  ?  ?  B  ?  ? 
 ?  B  O  B  ?  ?  ?  ? 
 ?  ?  O  ?  ?  ?  ?  B 
 ?  ?  O  ?  ?  ?  ?  ? 
 B  ?  O  ?  B  ?  ?  ? 
 ?  ?  O  ?  O  O  ?  ? 
 ?  B  ?  O  ?  B  O  B 
 ?  ?  O  B  O  B  O  X 
 ?  ?  O  W  ?  O  ?  B 


>>> Agent Physical Path 12:

>>> Physical path 12, Time: 0.144000 s, Min radius: 0.500000 Total Steps: 35.
 Step   1: Agent moved  DOWN to location [x=3,y=1], based on policy.
 Step   2: Agent moved DOWN_LEFT to location [x=2,y=2], based on policy.
 Step   3: Agent moved  LEFT to location [x=1,y=2], based on policy.
 Step   4: Agent moved UP_LEFT to location [x=0,y=1], based on policy.
 Step   5: Agent moved DOWN_RIGHT to location [x=1,y=2], randomly.
 Step   6: Agent moved RIGHT to location [x=2,y=2], based on policy.
 Step   7: Agent moved DOWN_RIGHT to location [x=3,y=3], based on policy.
 Step   8: Agent moved DOWN_RIGHT to location [x=4,y=4], based on policy.
 Step   9: Agent moved DOWN_RIGHT to location [x=5,y=5], based on policy.
 Step  10: Agent moved  DOWN to location [x=5,y=6], based on policy.
 Step  11: Agent moved UP_LEFT to location [x=4,y=5], randomly.
 Step  12: Agent moved  LEFT to location [x=3,y=5], based on policy.
 Step  13: Agent moved DOWN_LEFT to location [x=2,y=6], based on policy.
 Step  14: Agent moved  DOWN to location [x=2,y=7], based on policy.
 Step  15: Agent moved  DOWN to location [x=2,y=8], based on policy.
 Step  16: Agent moved  DOWN to location [x=2,y=9], based on policy.
 Step  17: Agent moved  DOWN to location [x=2,y=10], based on policy.
 Step  18: Agent moved  DOWN to location [x=2,y=11], based on policy.
 Step  19: Agent moved RIGHT to location [x=3,y=11], randomly.

>>> Agent Brain:
 ?  ?  ?  3  ?  ?  ?  ? 
 O  ?  ?  O  B  ?  ?  ? 
 ?  O  O  B  ?  ?  ?  ? 
 ?  B  ?  O  ?  B  ?  ? 
 ?  B  ?  B  O  ?  ?  ? 
 ?  ?  ?  O  O  O  ?  B 
 ?  ?  O  ?  ?  O  B  ? 
 B  ?  O  ?  B  ?  ?  ? 
 ?  ?  O  ?  ?  ?  ?  ? 
 ?  B  O  ?  ?  B  ?  B 
 ?  ?  O  B  ?  B  ?  ? 
 ?  ?  O  W  ?  ?  ?  B 


>>> Agent Physical Path 13:

>>> Physical path 13, Time: 0.579000 s, Min radius: 2.828427 Total Steps: 48.
 Step   1: Agent moved  DOWN to location [x=6,y=1], based on policy.
 Step   2: Agent moved DOWN_RIGHT to location [x=7,y=2], based on policy.
 Step   3: Agent moved  DOWN to location [x=7,y=3], based on policy.
 Step   4: Agent moved  DOWN to location [x=7,y=4], based on policy.
 Step   5: Agent moved UP_LEFT to location [x=6,y=3], randomly.
 Step   6: Agent moved    UP to location [x=6,y=2], based on policy.
 Step   7: Agent moved UP_RIGHT to location [x=7,y=1], based on policy.
 Step   8: Agent moved  LEFT to location [x=6,y=1], randomly.
 Step   9: Agent moved DOWN_LEFT to location [x=5,y=2], based on policy.
 Step  10: Agent moved DOWN_LEFT to location [x=4,y=3], based on policy.
 Step  11: Agent moved  DOWN to location [x=4,y=4], based on policy.
 Step  12: Agent moved DOWN_RIGHT to location [x=5,y=5], based on policy.
 Step  13: Agent moved  DOWN to location [x=5,y=6], based on policy.
 Step  14: Agent moved  DOWN to location [x=5,y=7], based on policy.
 Step  15: Agent moved  DOWN to location [x=5,y=8], based on policy.
 Step  16: Agent moved DOWN_LEFT to location [x=4,y=9], based on policy.
 Step  17: Agent moved  DOWN to location [x=4,y=10], based on policy.
 Step  18: Agent moved  DOWN to location [x=4,y=11], based on policy.
 Step  19: Agent moved RIGHT to location [x=5,y=11], randomly.
 Step  20: Agent moved RIGHT to location [x=6,y=11], based on policy.
 Step  21: Agent moved UP_RIGHT to location [x=7,y=10], randomly.
 Step  22: Agent moved  LEFT to location [x=6,y=10], randomly.
 Step  23: Agent moved DOWN_LEFT to location [x=5,y=11], based on policy.
 Step  24: Agent moved UP_LEFT to location [x=4,y=10], randomly.
 Step  25: Agent moved UP_LEFT to location [x=3,y=9], based on policy.
 Step  26: Agent moved UP_LEFT to location [x=2,y=8], based on policy.
 Step  27: Agent moved UP_LEFT to location [x=1,y=7], based on policy.
 Step  28: Agent moved    UP to location [x=1,y=6], based on policy.
 Step  29: Agent moved UP_LEFT to location [x=0,y=5], based on policy.
 Step  30: Agent moved RIGHT to location [x=1,y=5], randomly.
 Step  31: Agent moved DOWN_RIGHT to location [x=2,y=6], based on policy.
 Step  32: Agent moved  DOWN to location [x=2,y=7], based on policy.
 Step  33: Agent moved  DOWN to location [x=2,y=8], based on policy.
 Step  34: Agent moved  DOWN to location [x=2,y=9], based on policy.
 Step  35: Agent moved  DOWN to location [x=2,y=10], based on policy.
 Step  36: Agent moved  DOWN to location [x=2,y=11], based on policy.
 Step  37: Agent moved RIGHT to location [x=3,y=11], randomly.

>>> Agent Brain:
 ?  ?  ?  ?  ?  ?  3  ? 
 ?  ?  ?  ?  B  ?  O  O 
 ?  ?  ?  B  ?  O  O  O 
 ?  B  ?  ?  O  B  O  O 
 ?  B  ?  B  O  ?  ?  O 
 O  O  ?  ?  ?  O  ?  B 
 ?  O  O  ?  ?  O  B  ? 
 B  O  O  ?  B  O  ?  ? 
 ?  ?  O  ?  ?  O  ?  ? 
 ?  B  O  O  O  B  ?  B 
 ?  ?  O  B  O  B  O  X 
 ?  ?  O  W  O  O  H  B 


>>> Agent Physical Path 14:

>>> Physical path 14, Time: 0.439000 s, Min radius: 0.500000 Total Steps: 47.
 Step   1: Agent moved  DOWN to location [x=3,y=1], based on policy.
 Step   2: Agent moved DOWN_LEFT to location [x=2,y=2], based on policy.
 Step   3: Agent moved  LEFT to location [x=1,y=2], based on policy.
 Step   4: Agent moved UP_LEFT to location [x=0,y=1], based on policy.
 Step   5: Agent moved RIGHT to location [x=1,y=1], randomly.
 Step   6: Agent moved DOWN_RIGHT to location [x=2,y=2], based on policy.
 Step   7: Agent moved  DOWN to location [x=2,y=3], based on policy.
 Step   8: Agent moved  DOWN to location [x=2,y=4], based on policy.
 Step   9: Agent moved  DOWN to location [x=2,y=5], based on policy.
 Step  10: Agent moved  DOWN to location [x=2,y=6], based on policy.
 Step  11: Agent moved  DOWN to location [x=2,y=7], based on policy.
 Step  12: Agent moved  DOWN to location [x=2,y=8], based on policy.
 Step  13: Agent moved  DOWN to location [x=2,y=9], based on policy.
 Step  14: Agent moved  DOWN to location [x=2,y=10], based on policy.
 Step  15: Agent moved  DOWN to location [x=2,y=11], based on policy.
 Step  16: Agent moved    UP to location [x=2,y=10], randomly.
 Step  17: Agent moved UP_RIGHT to location [x=3,y=9], based on policy.
 Step  18: Agent moved RIGHT to location [x=4,y=9], based on policy.
 Step  19: Agent moved UP_RIGHT to location [x=5,y=8], randomly.
 Step  20: Agent moved RIGHT to location [x=6,y=8], based on policy.
 Step  21: Agent moved RIGHT to location [x=7,y=8], based on policy.
 Step  22: Agent moved    UP to location [x=7,y=7], randomly.
 Step  23: Agent moved DOWN_LEFT to location [x=6,y=8], randomly.
 Step  24: Agent moved  DOWN to location [x=6,y=9], based on policy.
 Step  25: Agent moved  DOWN to location [x=6,y=10], based on policy.
 Step  26: Agent moved  DOWN to location [x=6,y=11], based on policy.
 Step  27: Agent moved UP_RIGHT to location [x=7,y=10], randomly.
 Step  28: Agent moved DOWN_LEFT to location [x=6,y=11], randomly.
 Step  29: Agent moved  LEFT to location [x=5,y=11], randomly.
 Step  30: Agent moved  LEFT to location [x=4,y=11], based on policy.
 Step  31: Agent moved  LEFT to location [x=3,y=11], based on policy.

>>> Agent Brain:
 ?  ?  ?  3  ?  ?  ?  ? 
 O  O  ?  O  B  ?  ?  ? 
 ?  O  O  B  ?  ?  ?  ? 
 ?  B  O  ?  ?  B  ?  ? 
 ?  B  O  B  ?  ?  ?  ? 
 ?  ?  O  ?  ?  ?  ?  B 
 ?  ?  O  ?  ?  ?  B  ? 
 B  ?  O  ?  B  ?  ?  J 
 ?  ?  O  B  ?  O  O  O 
 ?  B  O  O  O  B  O  B 
 ?  B  O  B  ?  B  O  X 
 ?  ?  O  W  O  O  H  B 


>>> Agent Physical Path 15:

>>> Physical path 15, Time: 8.982000 s, Min radius: 7.009280 Total Steps: 63.
 Step   1: Agent moved  DOWN to location [x=6,y=1], based on policy.
 Step   2: Agent moved DOWN_RIGHT to location [x=7,y=2], based on policy.
 Step   3: Agent moved  DOWN to location [x=7,y=3], based on policy.
 Step   4: Agent moved  DOWN to location [x=7,y=4], based on policy.
 Step   5: Agent moved UP_LEFT to location [x=6,y=3], randomly.
 Step   6: Agent moved    UP to location [x=6,y=2], based on policy.
 Step   7: Agent moved UP_RIGHT to location [x=7,y=1], based on policy.
 Step   8: Agent moved DOWN_LEFT to location [x=6,y=2], randomly.
 Step   9: Agent moved  DOWN to location [x=6,y=3], based on policy.
 Step  10: Agent moved DOWN_RIGHT to location [x=7,y=4], based on policy.
 Step  11: Agent moved    UP to location [x=7,y=3], randomly.
 Step  12: Agent moved    UP to location [x=7,y=2], based on policy.
 Step  13: Agent moved UP_LEFT to location [x=6,y=1], based on policy.
 Step  14: Agent moved    UP to location [x=6,y=0], based on policy.
 Step  15: Agent moved DOWN_RIGHT to location [x=7,y=1], randomly.
 Step  16: Agent moved  DOWN to location [x=7,y=2], based on policy.
 Step  17: Agent moved  DOWN to location [x=7,y=3], based on policy.
 Step  18: Agent moved  DOWN to location [x=7,y=4], based on policy.
 Step  19: Agent moved    UP to location [x=7,y=3], randomly.
 Step  20: Agent moved    UP to location [x=7,y=2], based on policy.
 Step  21: Agent moved UP_LEFT to location [x=6,y=1], based on policy.
 Step  22: Agent moved    UP to location [x=6,y=0], based on policy.
 Step  23: Agent moved DOWN_RIGHT to location [x=7,y=1], randomly.
 Step  24: Agent moved  DOWN to location [x=7,y=2], based on policy.
 Step  25: Agent moved  DOWN to location [x=7,y=3], based on policy.
 Step  26: Agent moved  DOWN to location [x=7,y=4], based on policy.
 Step  27: Agent moved    UP to location [x=7,y=3], randomly.
 Step  28: Agent moved    UP to location [x=7,y=2], based on policy.
 Step  29: Agent moved UP_LEFT to location [x=6,y=1], based on policy.
 Step  30: Agent moved    UP to location [x=6,y=0], based on policy.
 Step  31: Agent moved  LEFT to location [x=5,y=0], randomly.
 Step  32: Agent moved  DOWN to location [x=5,y=1], randomly.
 Step  33: Agent moved DOWN_RIGHT to location [x=6,y=2], based on policy.
 Step  34: Agent moved DOWN_RIGHT to location [x=7,y=3], based on policy.
 Step  35: Agent moved  DOWN to location [x=7,y=4], based on policy.
 Step  36: Agent moved UP_LEFT to location [x=6,y=3], randomly.
 Step  37: Agent moved    UP to location [x=6,y=2], based on policy.
 Step  38: Agent moved UP_RIGHT to location [x=7,y=1], based on policy.
 Step  39: Agent moved DOWN_LEFT to location [x=6,y=2], randomly.
 Step  40: Agent moved  DOWN to location [x=6,y=3], based on policy.
 Step  41: Agent moved DOWN_RIGHT to location [x=7,y=4], based on policy.
 Step  42: Agent moved  LEFT to location [x=6,y=4], randomly.
 Step  43: Agent moved DOWN_LEFT to location [x=5,y=5], based on policy.
 Step  44: Agent moved  DOWN to location [x=5,y=6], based on policy.
 Step  45: Agent moved  DOWN to location [x=5,y=7], based on policy.
 Step  46: Agent moved DOWN_RIGHT to location [x=6,y=8], based on policy.
 Step  47: Agent moved  DOWN to location [x=6,y=9], based on policy.
 Step  48: Agent moved  DOWN to location [x=6,y=10], based on policy.
 Step  49: Agent moved  DOWN to location [x=6,y=11], based on policy.
 Step  50: Agent moved  LEFT to location [x=5,y=11], randomly.
 Step  51: Agent moved  LEFT to location [x=4,y=11], based on policy.
 Step  52: Agent moved  LEFT to location [x=3,y=11], based on policy.

>>> Agent Brain:
 ?  ?  ?  ?  ?  O  O  B 
 ?  ?  ?  ?  B  O  O  O 
 ?  ?  ?  B  ?  ?  O  O 
 ?  B  ?  ?  ?  B  O  O 
 ?  B  ?  B  ?  ?  O  O 
 ?  ?  ?  ?  ?  O  ?  B 
 ?  ?  ?  ?  ?  O  B  ? 
 B  ?  ?  ?  B  O  ?  ? 
 ?  ?  ?  B  ?  ?  O  ? 
 ?  B  ?  ?  ?  B  O  B 
 ?  B  ?  B  ?  B  O  ? 
 ?  ?  ?  W  O  O  H  B 


>>> Agent Physical Path 16:

>>> Physical path 16, Time: 6.692000 s, Min radius: 0.500000 Total Steps: 61.
 Step   1: Agent moved  DOWN to location [x=1,y=1], based on policy.
 Step   2: Agent moved DOWN_LEFT to location [x=0,y=2], based on policy.
 Step   3: Agent moved UP_RIGHT to location [x=1,y=1], randomly.
 Step   4: Agent moved RIGHT to location [x=2,y=1], based on policy.
 Step   5: Agent moved UP_RIGHT to location [x=3,y=0], based on policy.
 Step   6: Agent moved DOWN_LEFT to location [x=2,y=1], randomly.
 Step   7: Agent moved  LEFT to location [x=1,y=1], based on policy.
 Step   8: Agent moved DOWN_LEFT to location [x=0,y=2], based on policy.
 Step   9: Agent moved UP_RIGHT to location [x=1,y=1], randomly.
 Step  10: Agent moved RIGHT to location [x=2,y=1], based on policy.
 Step  11: Agent moved UP_RIGHT to location [x=3,y=0], based on policy.
 Step  12: Agent moved  LEFT to location [x=2,y=0], randomly.
 Step  13: Agent moved DOWN_LEFT to location [x=1,y=1], based on policy.
 Step  14: Agent moved DOWN_LEFT to location [x=0,y=2], based on policy.
 Step  15: Agent moved    UP to location [x=0,y=1], randomly.
 Step  16: Agent moved  DOWN to location [x=0,y=2], randomly.
 Step  17: Agent moved  DOWN to location [x=0,y=3], based on policy.
 Step  18: Agent moved  DOWN to location [x=0,y=4], based on policy.
 Step  19: Agent moved  DOWN to location [x=0,y=5], based on policy.
 Step  20: Agent moved  DOWN to location [x=0,y=6], based on policy.
 Step  21: Agent moved RIGHT to location [x=1,y=6], randomly.
 Step  22: Agent moved DOWN_RIGHT to location [x=2,y=7], based on policy.
 Step  23: Agent moved  DOWN to location [x=2,y=8], based on policy.
 Step  24: Agent moved  DOWN to location [x=2,y=9], based on policy.
 Step  25: Agent moved  DOWN to location [x=2,y=10], based on policy.
 Step  26: Agent moved  DOWN to location [x=2,y=11], based on policy.
 Step  27: Agent moved RIGHT to location [x=3,y=11], randomly.

>>> Agent Brain:
 ?  3  O  O  ?  ?  ?  B 
 O  O  O  ?  B  ?  ?  ? 
 O  ?  ?  B  ?  ?  ?  ? 
 O  B  ?  ?  ?  B  ?  ? 
 O  B  ?  B  ?  ?  ?  ? 
 O  ?  ?  ?  ?  ?  ?  B 
 O  O  ?  ?  ?  ?  B  ? 
 B  ?  O  ?  B  ?  ?  ? 
 ?  ?  O  B  ?  ?  ?  ? 
 ?  B  O  ?  ?  B  ?  B 
 ?  B  O  B  ?  B  ?  ? 
 ?  ?  O  W  ?  ?  ?  B 


>>> Agent Physical Path 17:

>>> Physical path 17, Time: 0.349000 s, Min radius: 2.828427 Total Steps: 47.
 Step   1: Agent moved  DOWN to location [x=5,y=1], based on policy.
 Step   2: Agent moved DOWN_RIGHT to location [x=6,y=2], based on policy.
 Step   3: Agent moved DOWN_RIGHT to location [x=7,y=3], based on policy.
 Step   4: Agent moved  DOWN to location [x=7,y=4], based on policy.
 Step   5: Agent moved UP_LEFT to location [x=6,y=3], randomly.
 Step   6: Agent moved    UP to location [x=6,y=2], based on policy.
 Step   7: Agent moved UP_RIGHT to location [x=7,y=1], based on policy.
 Step   8: Agent moved  LEFT to location [x=6,y=1], randomly.
 Step   9: Agent moved DOWN_LEFT to location [x=5,y=2], based on policy.
 Step  10: Agent moved DOWN_LEFT to location [x=4,y=3], based on policy.
 Step  11: Agent moved  DOWN to location [x=4,y=4], based on policy.
 Step  12: Agent moved DOWN_RIGHT to location [x=5,y=5], based on policy.
 Step  13: Agent moved  DOWN to location [x=5,y=6], based on policy.
 Step  14: Agent moved  DOWN to location [x=5,y=7], based on policy.
 Step  15: Agent moved DOWN_RIGHT to location [x=6,y=8], based on policy.
 Step  16: Agent moved  DOWN to location [x=6,y=9], based on policy.
 Step  17: Agent moved  DOWN to location [x=6,y=10], based on policy.
 Step  18: Agent moved  DOWN to location [x=6,y=11], based on policy.
 Step  19: Agent moved  LEFT to location [x=5,y=11], randomly.
 Step  20: Agent moved  LEFT to location [x=4,y=11], based on policy.
 Step  21: Agent moved  LEFT to location [x=3,y=11], based on policy.

>>> Agent Brain:
 ?  ?  ?  ?  ?  3  ?  B 
 ?  ?  ?  ?  B  O  O  O 
 ?  ?  ?  B  ?  O  O  ? 
 ?  B  ?  ?  O  B  O  O 
 ?  B  ?  B  O  ?  ?  O 
 ?  ?  ?  ?  ?  O  ?  B 
 ?  ?  ?  ?  ?  O  B  ? 
 B  ?  ?  ?  B  O  ?  ? 
 ?  ?  ?  B  ?  ?  O  ? 
 ?  B  ?  ?  ?  B  O  B 
 ?  B  ?  B  ?  B  O  ? 
 ?  ?  ?  W  O  O  H  B 


>>> Agent Physical Path 18:

>>> Physical path 18, Time: 0.263000 s, Min radius: 0.500000 Total Steps: 36.
 Step   1: Agent moved  DOWN to location [x=3,y=1], based on policy.
 Step   2: Agent moved DOWN_LEFT to location [x=2,y=2], based on policy.
 Step   3: Agent moved  LEFT to location [x=1,y=2], based on policy.
 Step   4: Agent moved UP_LEFT to location [x=0,y=1], based on policy.
 Step   5: Agent moved DOWN_RIGHT to location [x=1,y=2], randomly.
 Step   6: Agent moved RIGHT to location [x=2,y=2], based on policy.
 Step   7: Agent moved DOWN_RIGHT to location [x=3,y=3], based on policy.
 Step   8: Agent moved DOWN_RIGHT to location [x=4,y=4], based on policy.
 Step   9: Agent moved DOWN_RIGHT to location [x=5,y=5], based on policy.
 Step  10: Agent moved  DOWN to location [x=5,y=6], based on policy.
 Step  11: Agent moved UP_LEFT to location [x=4,y=5], randomly.
 Step  12: Agent moved  LEFT to location [x=3,y=5], based on policy.
 Step  13: Agent moved DOWN_LEFT to location [x=2,y=6], based on policy.
 Step  14: Agent moved  DOWN to location [x=2,y=7], based on policy.
 Step  15: Agent moved  DOWN to location [x=2,y=8], based on policy.
 Step  16: Agent moved  DOWN to location [x=2,y=9], based on policy.
 Step  17: Agent moved  DOWN to location [x=2,y=10], based on policy.
 Step  18: Agent moved  DOWN to location [x=2,y=11], based on policy.
 Step  19: Agent moved RIGHT to location [x=3,y=11], randomly.

>>> Agent Brain:
 ?  ?  ?  3  ?  ?  ?  B 
 O  ?  ?  O  B  ?  ?  ? 
 ?  O  O  B  ?  ?  ?  ? 
 ?  B  ?  O  ?  B  ?  ? 
 ?  B  ?  B  O  ?  ?  ? 
 ?  ?  ?  O  O  O  ?  B 
 ?  ?  O  ?  ?  O  B  ? 
 B  ?  O  ?  B  ?  ?  ? 
 ?  ?  O  B  ?  ?  ?  ? 
 ?  B  O  ?  ?  B  ?  B 
 ?  B  O  B  ?  B  ?  ? 
 ?  ?  O  W  ?  ?  ?  B 


>>> Agent Physical Path 19:

>>> Physical path 19, Time: 0.258000 s, Min radius: 0.500000 Total Steps: 59.
 Step   1: Agent moved  DOWN to location [x=3,y=1], based on policy.
 Step   2: Agent moved DOWN_LEFT to location [x=2,y=2], based on policy.
 Step   3: Agent moved  LEFT to location [x=1,y=2], based on policy.
 Step   4: Agent moved UP_LEFT to location [x=0,y=1], based on policy.
 Step   5: Agent moved RIGHT to location [x=1,y=1], randomly.
 Step   6: Agent moved DOWN_RIGHT to location [x=2,y=2], based on policy.
 Step   7: Agent moved  DOWN to location [x=2,y=3], based on policy.
 Step   8: Agent moved  DOWN to location [x=2,y=4], based on policy.
 Step   9: Agent moved  DOWN to location [x=2,y=5], based on policy.
 Step  10: Agent moved  DOWN to location [x=2,y=6], based on policy.
 Step  11: Agent moved  DOWN to location [x=2,y=7], based on policy.
 Step  12: Agent moved DOWN_LEFT to location [x=1,y=8], based on policy.
 Step  13: Agent moved DOWN_LEFT to location [x=0,y=9], based on policy.
 Step  14: Agent moved  DOWN to location [x=0,y=10], based on policy.
 Step  15: Agent moved  DOWN to location [x=0,y=11], based on policy.
 Step  16: Agent moved RIGHT to location [x=1,y=11], randomly.
 Step  17: Agent moved RIGHT to location [x=2,y=11], based on policy.
 Step  18: Agent moved RIGHT to location [x=3,y=11], based on policy.

>>> Agent Brain:
 ?  ?  ?  3  ?  ?  ?  B 
 O  O  ?  O  B  ?  ?  ? 
 ?  O  O  B  ?  ?  ?  ? 
 ?  B  O  ?  ?  B  ?  ? 
 ?  B  O  B  ?  ?  ?  ? 
 ?  ?  O  ?  ?  ?  ?  B 
 ?  ?  O  ?  ?  ?  B  ? 
 B  ?  O  ?  B  ?  ?  ? 
 ?  O  ?  B  ?  ?  ?  ? 
 O  B  ?  ?  ?  B  ?  B 
 O  B  ?  B  ?  B  ?  ? 
 O  E  O  W  ?  ?  ?  B 


>>> Agent Physical Path 20:

>>> Physical path 20, Time: 1.301000 s, Min radius: 0.500000 Total Steps: 51.
 Step   1: Agent moved  DOWN to location [x=3,y=1], based on policy.
 Step   2: Agent moved DOWN_LEFT to location [x=2,y=2], based on policy.
 Step   3: Agent moved  LEFT to location [x=1,y=2], based on policy.
 Step   4: Agent moved UP_LEFT to location [x=0,y=1], based on policy.
 Step   5: Agent moved    UP to location [x=0,y=0], randomly.
 Step   6: Agent moved RIGHT to location [x=1,y=0], randomly.
 Step   7: Agent moved DOWN_RIGHT to location [x=2,y=1], based on policy.
 Step   8: Agent moved  DOWN to location [x=2,y=2], based on policy.
 Step   9: Agent moved  DOWN to location [x=2,y=3], based on policy.
 Step  10: Agent moved  DOWN to location [x=2,y=4], based on policy.
 Step  11: Agent moved  DOWN to location [x=2,y=5], based on policy.
 Step  12: Agent moved  DOWN to location [x=2,y=6], based on policy.
 Step  13: Agent moved  DOWN to location [x=2,y=7], based on policy.
 Step  14: Agent moved DOWN_LEFT to location [x=1,y=8], based on policy.
 Step  15: Agent moved DOWN_LEFT to location [x=0,y=9], based on policy.
 Step  16: Agent moved  DOWN to location [x=0,y=10], based on policy.
 Step  17: Agent moved  DOWN to location [x=0,y=11], based on policy.
 Step  18: Agent moved    UP to location [x=0,y=10], randomly.
 Step  19: Agent moved    UP to location [x=0,y=9], based on policy.
 Step  20: Agent moved    UP to location [x=0,y=8], based on policy.
 Step  21: Agent moved UP_RIGHT to location [x=1,y=7], based on policy.
 Step  22: Agent moved RIGHT to location [x=2,y=7], based on policy.
 Step  23: Agent moved RIGHT to location [x=3,y=7], based on policy.
 Step  24: Agent moved UP_RIGHT to location [x=4,y=6], based on policy.
 Step  25: Agent moved    UP to location [x=4,y=5], based on policy.
 Step  26: Agent moved DOWN_LEFT to location [x=3,y=6], randomly.
 Step  27: Agent moved DOWN_LEFT to location [x=2,y=7], based on policy.
 Step  28: Agent moved DOWN_LEFT to location [x=1,y=8], based on policy.
 Step  29: Agent moved DOWN_LEFT to location [x=0,y=9], based on policy.
 Step  30: Agent moved  DOWN to location [x=0,y=10], based on policy.
 Step  31: Agent moved  DOWN to location [x=0,y=11], based on policy.
 Step  32: Agent moved RIGHT to location [x=1,y=11], randomly.
 Step  33: Agent moved RIGHT to location [x=2,y=11], based on policy.
 Step  34: Agent moved RIGHT to location [x=3,y=11], based on policy.

>>> Agent Brain:
 O  O  ?  3  ?  ?  ?  B 
 O  ?  O  O  B  ?  ?  ? 
 ?  O  O  B  ?  ?  ?  ? 
 ?  B  O  ?  ?  B  ?  ? 
 ?  B  O  B  ?  B  ?  ? 
 ?  ?  O  ?  O  ?  ?  B 
 ?  ?  O  O  O  ?  B  ? 
 B  O  O  O  B  ?  ?  ? 
 O  O  ?  B  ?  ?  ?  ? 
 O  B  ?  ?  ?  B  ?  B 
 O  B  ?  B  ?  B  ?  ? 
 O  E  O  W  ?  ?  ?  B 

>>> Process Time: 45.485000 s.
