
>>> Values:
 Random Seed Value = 24560
 Number of Physical Paths = 5
 Number of Learning Paths per Physical Path = 1
 Method = 5
 Number of Lookahead Levels = 1
 Path-File Mode = 3
 Step-Size Parameter ALPHA = 0.100000
 Discount Rate GAMMA = 0.900000
 Lookahead Weight Factor LAMBDA = 0.500000
 Q-value Weight Factor w1 = 0.800000
 Distance-to-Goal Weight Factor w2 = 0.500000
 Initial Full Exploration is OFF
 Visited-Number Weight factor w3 = 0.500000
 TAW has greedy-mode value = 1
 Star is 1 at location [4, 0]
 Goal is H

>>> Input Maze:
 O  O  O  O  O  O  B  B 
 B  O  O  O  B  O  B  J 
 O  O  O  B  O  O  O  O 
 O  B  O  O  O  B  O  B 
 O  B  O  B  O  B  O  X 
 O  E  O  W  O  O  H  B 


>>> Agent Physical Path 1:

>>> Physical path 1, Time: 1.029000 s, Min radius: 7.453560 Total Steps: 324.
 Step   1: Agent moved DOWN_RIGHT to location [x=5,y=1], randomly.
 Step   2: Agent moved DOWN_RIGHT to location [x=6,y=2], randomly.
 Step   3: Agent moved  LEFT to location [x=5,y=2], randomly.
 Step   4: Agent moved DOWN_RIGHT to location [x=6,y=3], randomly.
 Step   5: Agent moved  DOWN to location [x=6,y=4], randomly.
 Step   6: Agent moved  DOWN to location [x=6,y=5], randomly.

>>> Agent Brain:
 ?  ?  ?  ?  1  ?  ?  ? 
 ?  ?  ?  ?  B  O  B  ? 
 ?  ?  ?  ?  ?  O  O  ? 
 ?  ?  ?  ?  ?  ?  O  ? 
 ?  ?  ?  ?  ?  ?  O  ? 
 ?  ?  ?  ?  ?  ?  H  ? 


>>> Agent Physical Path 2:

>>> Physical path 2, Time: 1.155000 s, Min radius: 0.333333 Total Steps: 181.
 Step   1: Agent moved  DOWN to location [x=5,y=1], based on policy.
 Step   2: Agent moved  DOWN to location [x=5,y=2], based on policy.
 Step   3: Agent moved DOWN_RIGHT to location [x=6,y=3], based on policy.
 Step   4: Agent moved DOWN_RIGHT to location [x=7,y=4], based on policy.
 Step   5: Agent moved UP_LEFT to location [x=6,y=3], randomly.
 Step   6: Agent moved UP_LEFT to location [x=5,y=2], based on policy.
 Step   7: Agent moved    UP to location [x=5,y=1], based on policy.
 Step   8: Agent moved UP_LEFT to location [x=4,y=0], based on policy.
 Step   9: Agent moved  LEFT to location [x=3,y=0], based on policy.
 Step  10: Agent moved DOWN_LEFT to location [x=2,y=1], based on policy.
 Step  11: Agent moved  DOWN to location [x=2,y=2], based on policy.
 Step  12: Agent moved DOWN_RIGHT to location [x=3,y=3], based on policy.
 Step  13: Agent moved DOWN_RIGHT to location [x=4,y=4], based on policy.
 Step  14: Agent moved DOWN_RIGHT to location [x=5,y=5], based on policy.
 Step  15: Agent moved RIGHT to location [x=6,y=5], based on policy.

>>> Agent Brain:
 ?  ?  ?  O  O  1  ?  ? 
 ?  ?  O  ?  ?  O  ?  ? 
 ?  ?  O  ?  ?  O  ?  ? 
 ?  ?  ?  O  ?  B  O  B 
 ?  ?  ?  ?  O  ?  ?  X 
 ?  ?  ?  ?  ?  O  H  B 


>>> Agent Physical Path 3:

>>> Physical path 3, Time: 0.094000 s, Min radius: 5.656854 Total Steps: 76.
 Step   1: Agent moved DOWN_RIGHT to location [x=3,y=1], based on policy.
 Step   2: Agent moved DOWN_RIGHT to location [x=4,y=2], based on policy.
 Step   3: Agent moved  DOWN to location [x=4,y=3], based on policy.
 Step   4: Agent moved  DOWN to location [x=4,y=4], based on policy.
 Step   5: Agent moved DOWN_RIGHT to location [x=5,y=5], based on policy.
 Step   6: Agent moved RIGHT to location [x=6,y=5], based on policy.

>>> Agent Brain:
 ?  ?  1  ?  ?  ?  ?  ? 
 ?  ?  ?  O  ?  ?  ?  ? 
 ?  ?  ?  ?  O  ?  ?  ? 
 ?  ?  ?  ?  O  B  ?  B 
 ?  ?  ?  B  O  ?  ?  ? 
 ?  ?  ?  ?  ?  O  H  B 


>>> Agent Physical Path 4:

Warning: moveAgent: Agent reached maximum number of steps before reaching Goal (step = 1199).

>>> Physical path 4, Time: 2.528000 s, Min radius: 0.333333 Total Steps: 1430.

>>> Physical path 4, Time: 2.559000 s, Min radius: 8.000000 Total Steps: 1435.
 Step   1: Agent moved DOWN_RIGHT to location [x=5,y=1], based on policy.
 Step   2: Agent moved  DOWN to location [x=5,y=2], based on policy.
 Step   3: Agent moved DOWN_RIGHT to location [x=6,y=3], based on policy.
 Step   4: Agent moved DOWN_RIGHT to location [x=7,y=4], based on policy.
 Step   5: Agent moved DOWN_LEFT to location [x=6,y=5], randomly.

>>> Agent Brain:
 1  ?  ?  O  O  ?  B  ? 
 ?  O  O  ?  ?  O  ?  ? 
 ?  ?  O  ?  ?  O  ?  ? 
 ?  ?  ?  O  O  B  O  B 
 ?  ?  ?  B  ?  B  ?  X 
 ?  ?  ?  ?  ?  ?  H  B 


>>> Agent Physical Path 5:

Warning: moveAgent: Agent reached maximum number of steps before reaching Goal (step = 1199).

>>> Physical path 5, Time: 2.574000 s, Min radius: 0.333333 Total Steps: 1307.

>>> Physical path 5, Time: 3.728000 s, Min radius: 0.707107 Total Steps: 1320.
 Step   1: Agent moved RIGHT to location [x=5,y=0], based on policy.
 Step   2: Agent moved  LEFT to location [x=4,y=0], randomly.
 Step   3: Agent moved DOWN_LEFT to location [x=3,y=1], based on policy.
 Step   4: Agent moved  LEFT to location [x=2,y=1], based on policy.
 Step   5: Agent moved DOWN_LEFT to location [x=1,y=2], based on policy.
 Step   6: Agent moved DOWN_LEFT to location [x=0,y=3], based on policy.
 Step   7: Agent moved  DOWN to location [x=0,y=4], based on policy.
 Step   8: Agent moved DOWN_RIGHT to location [x=1,y=5], based on policy.
 Step   9: Agent moved RIGHT to location [x=2,y=5], based on policy.
 Step  10: Agent moved RIGHT to location [x=3,y=5], randomly.
 Step  11: Agent moved RIGHT to location [x=4,y=5], based on policy.
 Step  12: Agent moved RIGHT to location [x=5,y=5], based on policy.
 Step  13: Agent moved RIGHT to location [x=6,y=5], based on policy.

>>> Agent Brain:
 1  ?  ?  O  O  O  B  ? 
 ?  O  O  O  ?  O  B  ? 
 ?  O  O  B  ?  O  ?  ? 
 O  ?  ?  O  O  B  ?  B 
 O  B  ?  B  ?  B  ?  ? 
 ?  E  O  W  O  O  H  B 

>>> Process Time: 214.032000 s.
