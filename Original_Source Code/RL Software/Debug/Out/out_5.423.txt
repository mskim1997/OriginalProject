
>>> Values:
 Random Seed Value = 51566
 Number of Physical Paths = 5
 Number of Learning Paths per Physical Path = 1
 Method = 5
 Number of Lookahead Levels = 1
 Path-File Mode = 3
 Step-Size Parameter ALPHA = 0.100000
 Discount Rate GAMMA = 0.900000
 Lookahead Weight Factor LAMBDA = 0.500000
 Q-value Weight Factor w1 = 0.800000
 Distance-to-Goal Weight Factor w2 = 0.500000
 Initial Full Exploration is OFF
 Visited-Number Weight factor w3 = 0.500000
 TAW has greedy-mode value = 1
 Star is R at location [0, 2]
 Goal is W

>>> Input Maze:
 C  O  O  A  O  D  B  B 
 B  O  O  O  B  O  B  P 
 R  O  O  B  O  O  O  O 
 O  B  O  O  O  B  O  B 
 O  B  O  B  O  B  O  O 
 O  O  O  O  O  O  O  O 


>>> Agent Physical Path 1:

>>> Physical path 1, Time: 9.608000 s, Min radius: 0.333333 Total Steps: 45.
 Step   1: Agent moved  DOWN to location [x=0,y=3], randomly.
 Step   2: Agent moved UP_RIGHT to location [x=1,y=2], randomly.
 Step   3: Agent moved  LEFT to location [x=0,y=2], randomly.
 Step   4: Agent moved RIGHT to location [x=1,y=2], randomly.
 Step   5: Agent moved DOWN_RIGHT to location [x=2,y=3], randomly.
 Step   6: Agent moved  DOWN to location [x=2,y=4], randomly.
 Step   7: Agent moved  DOWN to location [x=2,y=5], randomly.
 Step   8: Agent moved RIGHT to location [x=3,y=5], randomly.
 Step   9: Agent moved DOWN_RIGHT to location [x=0,y=0], randomly.

>>> Agent Brain:
 ?  ?  ?  ?  ?  ?  ?  ? 
 B  ?  ?  ?  ?  ?  ?  ? 
 R  O  ?  ?  ?  ?  ?  ? 
 O  B  O  ?  ?  ?  ?  ? 
 ?  B  O  ?  ?  ?  ?  ? 
 ?  ?  O  O  ?  ?  ?  ? 


>>> Agent Physical Path 2:

>>> Physical path 2, Time: 31.486000 s, Min radius: 0.942809 Total Steps: 77.
 Step   1: Agent moved  DOWN to location [x=0,y=3], randomly.
 Step   2: Agent moved  DOWN to location [x=0,y=4], based on policy.
 Step   3: Agent moved  DOWN to location [x=0,y=5], based on policy.
 Step   4: Agent moved DOWN_RIGHT to location [x=1,y=2], based on policy.

>>> Agent Brain:
 ?  ?  ?  ?  ?  ?  ?  ? 
 ?  ?  ?  ?  ?  ?  ?  ? 
 R  ?  ?  ?  ?  ?  ?  ? 
 O  B  ?  ?  ?  ?  ?  ? 
 O  ?  ?  ?  ?  ?  ?  ? 
 O  ?  ?  ?  ?  ?  ?  ? 


>>> Agent Physical Path 3:

>>> Physical path 3, Time: 22.602000 s, Min radius: 0.333333 Total Steps: 199.
 Step   1: Agent moved RIGHT to location [x=1,y=2], randomly.
 Step   2: Agent moved UP_RIGHT to location [x=2,y=1], based on policy.
 Step   3: Agent moved    UP to location [x=2,y=0], based on policy.
 Step   4: Agent moved DOWN_RIGHT to location [x=3,y=1], randomly.
 Step   5: Agent moved  LEFT to location [x=2,y=1], randomly.
 Step   6: Agent moved UP_LEFT to location [x=1,y=0], based on policy.
 Step   7: Agent moved  LEFT to location [x=0,y=0], based on policy.
 Step   8: Agent moved DOWN_RIGHT to location [x=1,y=1], randomly.
 Step   9: Agent moved RIGHT to location [x=2,y=1], based on policy.
 Step  10: Agent moved UP_RIGHT to location [x=3,y=0], based on policy.
 Step  11: Agent moved  LEFT to location [x=2,y=0], randomly.
 Step  12: Agent moved  LEFT to location [x=1,y=0], based on policy.
 Step  13: Agent moved  LEFT to location [x=0,y=0], based on policy.
 Step  14: Agent moved RIGHT to location [x=1,y=0], randomly.
 Step  15: Agent moved RIGHT to location [x=2,y=0], based on policy.
 Step  16: Agent moved RIGHT to location [x=3,y=0], based on policy.
 Step  17: Agent moved RIGHT to location [x=4,y=0], based on policy.
 Step  18: Agent moved RIGHT to location [x=5,y=0], based on policy.
 Step  19: Agent moved  LEFT to location [x=4,y=0], randomly.
 Step  20: Agent moved  LEFT to location [x=3,y=0], based on policy.
 Step  21: Agent moved  LEFT to location [x=2,y=0], based on policy.
 Step  22: Agent moved  LEFT to location [x=1,y=0], based on policy.
 Step  23: Agent moved  LEFT to location [x=0,y=0], based on policy.
 Step  24: Agent moved RIGHT to location [x=1,y=0], randomly.
 Step  25: Agent moved RIGHT to location [x=2,y=0], based on policy.
 Step  26: Agent moved DOWN_RIGHT to location [x=3,y=1], based on policy.
 Step  27: Agent moved UP_RIGHT to location [x=4,y=0], randomly.
 Step  28: Agent moved RIGHT to location [x=5,y=0], randomly.
 Step  29: Agent moved  LEFT to location [x=4,y=0], randomly.
 Step  30: Agent moved  LEFT to location [x=3,y=0], based on policy.
 Step  31: Agent moved  LEFT to location [x=2,y=0], based on policy.
 Step  32: Agent moved  LEFT to location [x=1,y=0], based on policy.
 Step  33: Agent moved  LEFT to location [x=0,y=0], based on policy.
 Step  34: Agent moved RIGHT to location [x=1,y=0], randomly.
 Step  35: Agent moved RIGHT to location [x=2,y=0], based on policy.
 Step  36: Agent moved RIGHT to location [x=3,y=0], based on policy.
 Step  37: Agent moved RIGHT to location [x=4,y=0], based on policy.
 Step  38: Agent moved RIGHT to location [x=5,y=0], based on policy.
 Step  39: Agent moved  LEFT to location [x=4,y=0], randomly.
 Step  40: Agent moved  LEFT to location [x=3,y=0], based on policy.
 Step  41: Agent moved  LEFT to location [x=2,y=0], based on policy.
 Step  42: Agent moved  LEFT to location [x=1,y=0], based on policy.
 Step  43: Agent moved  LEFT to location [x=0,y=0], based on policy.
 Step  44: Agent moved DOWN_RIGHT to location [x=1,y=1], randomly.
 Step  45: Agent moved RIGHT to location [x=2,y=1], based on policy.
 Step  46: Agent moved UP_RIGHT to location [x=3,y=0], based on policy.
 Step  47: Agent moved  LEFT to location [x=2,y=0], randomly.
 Step  48: Agent moved  LEFT to location [x=1,y=0], based on policy.
 Step  49: Agent moved  LEFT to location [x=0,y=0], based on policy.
 Step  50: Agent moved RIGHT to location [x=1,y=0], randomly.
 Step  51: Agent moved RIGHT to location [x=2,y=0], based on policy.
 Step  52: Agent moved RIGHT to location [x=3,y=0], based on policy.
 Step  53: Agent moved RIGHT to location [x=4,y=0], based on policy.
 Step  54: Agent moved RIGHT to location [x=5,y=0], based on policy.
 Step  55: Agent moved  LEFT to location [x=4,y=0], randomly.
 Step  56: Agent moved  LEFT to location [x=3,y=0], based on policy.
 Step  57: Agent moved  LEFT to location [x=2,y=0], based on policy.
 Step  58: Agent moved  LEFT to location [x=1,y=0], based on policy.
 Step  59: Agent moved  LEFT to location [x=0,y=0], based on policy.
 Step  60: Agent moved RIGHT to location [x=1,y=0], randomly.
 Step  61: Agent moved RIGHT to location [x=2,y=0], based on policy.
 Step  62: Agent moved RIGHT to location [x=3,y=0], based on policy.
 Step  63: Agent moved RIGHT to location [x=4,y=0], based on policy.
 Step  64: Agent moved RIGHT to location [x=5,y=0], based on policy.
 Step  65: Agent moved  LEFT to location [x=4,y=0], randomly.
 Step  66: Agent moved  LEFT to location [x=3,y=0], based on policy.
 Step  67: Agent moved  LEFT to location [x=2,y=0], based on policy.
 Step  68: Agent moved  LEFT to location [x=1,y=0], based on policy.
 Step  69: Agent moved  LEFT to location [x=0,y=0], based on policy.
 Step  70: Agent moved DOWN_RIGHT to location [x=1,y=1], randomly.
 Step  71: Agent moved RIGHT to location [x=2,y=1], based on policy.
 Step  72: Agent moved UP_RIGHT to location [x=3,y=0], based on policy.
 Step  73: Agent moved RIGHT to location [x=4,y=0], randomly.
 Step  74: Agent moved RIGHT to location [x=5,y=0], based on policy.
 Step  75: Agent moved  LEFT to location [x=4,y=0], randomly.
 Step  76: Agent moved  LEFT to location [x=3,y=0], based on policy.
 Step  77: Agent moved  LEFT to location [x=2,y=0], based on policy.
 Step  78: Agent moved  LEFT to location [x=1,y=0], based on policy.
 Step  79: Agent moved  LEFT to location [x=0,y=0], based on policy.
 Step  80: Agent moved DOWN_RIGHT to location [x=1,y=1], randomly.
 Step  81: Agent moved RIGHT to location [x=2,y=1], based on policy.
 Step  82: Agent moved UP_RIGHT to location [x=3,y=0], based on policy.
 Step  83: Agent moved DOWN_LEFT to location [x=2,y=1], randomly.
 Step  84: Agent moved  LEFT to location [x=1,y=1], based on policy.
 Step  85: Agent moved UP_LEFT to location [x=0,y=0], based on policy.
 Step  86: Agent moved DOWN_RIGHT to location [x=1,y=1], randomly.
 Step  87: Agent moved RIGHT to location [x=2,y=1], based on policy.
 Step  88: Agent moved UP_RIGHT to location [x=3,y=0], based on policy.
 Step  89: Agent moved  LEFT to location [x=2,y=0], randomly.
 Step  90: Agent moved  LEFT to location [x=1,y=0], based on policy.
 Step  91: Agent moved  LEFT to location [x=0,y=0], based on policy.
 Step  92: Agent moved RIGHT to location [x=1,y=0], randomly.
 Step  93: Agent moved RIGHT to location [x=2,y=0], based on policy.
 Step  94: Agent moved RIGHT to location [x=3,y=0], based on policy.
 Step  95: Agent moved RIGHT to location [x=4,y=0], based on policy.
 Step  96: Agent moved RIGHT to location [x=5,y=0], based on policy.
 Step  97: Agent moved  DOWN to location [x=5,y=1], randomly.
 Step  98: Agent moved DOWN_LEFT to location [x=4,y=2], based on policy.
 Step  99: Agent moved  DOWN to location [x=4,y=3], based on policy.
 Step 100: Agent moved UP_RIGHT to location [x=5,y=2], randomly.
 Step 101: Agent moved    UP to location [x=5,y=1], based on policy.
 Step 102: Agent moved UP_LEFT to location [x=4,y=0], based on policy.
 Step 103: Agent moved RIGHT to location [x=5,y=0], randomly.
 Step 104: Agent moved  LEFT to location [x=4,y=0], randomly.
 Step 105: Agent moved  LEFT to location [x=3,y=0], based on policy.
 Step 106: Agent moved  LEFT to location [x=2,y=0], based on policy.
 Step 107: Agent moved  LEFT to location [x=1,y=0], based on policy.
 Step 108: Agent moved  DOWN to location [x=1,y=1], randomly.
 Step 109: Agent moved DOWN_RIGHT to location [x=2,y=2], based on policy.
 Step 110: Agent moved  DOWN to location [x=2,y=3], based on policy.
 Step 111: Agent moved UP_LEFT to location [x=1,y=2], randomly.
 Step 112: Agent moved  LEFT to location [x=0,y=2], based on policy.
 Step 113: Agent moved UP_RIGHT to location [x=1,y=1], randomly.
 Step 114: Agent moved    UP to location [x=1,y=0], based on policy.
 Step 115: Agent moved DOWN_RIGHT to location [x=2,y=1], randomly.
 Step 116: Agent moved  DOWN to location [x=2,y=2], based on policy.
 Step 117: Agent moved  DOWN to location [x=2,y=3], based on policy.
 Step 118: Agent moved RIGHT to location [x=3,y=3], randomly.
 Step 119: Agent moved UP_RIGHT to location [x=4,y=2], based on policy.
 Step 120: Agent moved UP_RIGHT to location [x=5,y=1], based on policy.
 Step 121: Agent moved    UP to location [x=5,y=0], based on policy.
 Step 122: Agent moved  DOWN to location [x=5,y=1], randomly.
 Step 123: Agent moved DOWN_LEFT to location [x=4,y=2], based on policy.
 Step 124: Agent moved DOWN_LEFT to location [x=3,y=3], based on policy.
 Step 125: Agent moved DOWN_LEFT to location [x=2,y=4], based on policy.
 Step 126: Agent moved DOWN_LEFT to location [x=1,y=5], based on policy.
 Step 127: Agent moved DOWN_LEFT to location [x=0,y=0], based on policy.

>>> Agent Brain:
 C  O  O  A  O  D  B  ? 
 B  O  O  O  B  O  B  ? 
 R  O  O  B  O  O  ?  ? 
 ?  B  O  O  O  B  ?  ? 
 ?  B  O  B  ?  B  ?  ? 
 ?  O  ?  ?  ?  ?  ?  ? 


>>> Agent Physical Path 4:

>>> Physical path 4, Time: 20.621000 s, Min radius: 0.333333 Total Steps: 87.
 Step   1: Agent moved UP_RIGHT to location [x=1,y=1], randomly.
 Step   2: Agent moved    UP to location [x=1,y=0], based on policy.
 Step   3: Agent moved  DOWN to location [x=1,y=1], randomly.
 Step   4: Agent moved DOWN_RIGHT to location [x=2,y=2], based on policy.
 Step   5: Agent moved  DOWN to location [x=2,y=3], based on policy.
 Step   6: Agent moved    UP to location [x=2,y=2], randomly.
 Step   7: Agent moved    UP to location [x=2,y=1], based on policy.
 Step   8: Agent moved UP_LEFT to location [x=1,y=0], based on policy.
 Step   9: Agent moved  LEFT to location [x=0,y=0], based on policy.
 Step  10: Agent moved RIGHT to location [x=1,y=0], randomly.
 Step  11: Agent moved RIGHT to location [x=2,y=0], based on policy.
 Step  12: Agent moved RIGHT to location [x=3,y=0], based on policy.
 Step  13: Agent moved RIGHT to location [x=4,y=0], based on policy.
 Step  14: Agent moved RIGHT to location [x=5,y=0], based on policy.
 Step  15: Agent moved  LEFT to location [x=4,y=0], randomly.
 Step  16: Agent moved  LEFT to location [x=3,y=0], based on policy.
 Step  17: Agent moved  LEFT to location [x=2,y=0], based on policy.
 Step  18: Agent moved  LEFT to location [x=1,y=0], based on policy.
 Step  19: Agent moved  LEFT to location [x=0,y=0], based on policy.
 Step  20: Agent moved DOWN_RIGHT to location [x=1,y=1], randomly.
 Step  21: Agent moved RIGHT to location [x=2,y=1], based on policy.
 Step  22: Agent moved UP_RIGHT to location [x=3,y=0], based on policy.
 Step  23: Agent moved  DOWN to location [x=3,y=1], randomly.
 Step  24: Agent moved DOWN_RIGHT to location [x=4,y=2], based on policy.
 Step  25: Agent moved  DOWN to location [x=4,y=3], based on policy.
 Step  26: Agent moved  DOWN to location [x=4,y=4], randomly.
 Step  27: Agent moved DOWN_LEFT to location [x=3,y=5], based on policy.
 Step  28: Agent moved DOWN_LEFT to location [x=5,y=0], based on policy.

>>> Agent Brain:
 C  O  O  A  O  D  B  ? 
 B  O  O  O  B  ?  B  ? 
 R  ?  O  B  O  ?  ?  ? 
 ?  B  O  ?  O  B  ?  ? 
 ?  B  ?  B  O  B  ?  ? 
 ?  ?  ?  O  ?  ?  ?  ? 


>>> Agent Physical Path 5:

>>> Physical path 5, Time: 13.204000 s, Min radius: 0.333333 Total Steps: 46.
 Step   1: Agent moved UP_RIGHT to location [x=1,y=1], randomly.
 Step   2: Agent moved    UP to location [x=1,y=0], based on policy.
 Step   3: Agent moved RIGHT to location [x=2,y=0], randomly.
 Step   4: Agent moved RIGHT to location [x=3,y=0], based on policy.
 Step   5: Agent moved RIGHT to location [x=4,y=0], based on policy.
 Step   6: Agent moved RIGHT to location [x=5,y=0], based on policy.
 Step   7: Agent moved  DOWN to location [x=5,y=1], randomly.
 Step   8: Agent moved DOWN_LEFT to location [x=4,y=2], based on policy.
 Step   9: Agent moved DOWN_LEFT to location [x=3,y=3], based on policy.
 Step  10: Agent moved DOWN_LEFT to location [x=2,y=4], based on policy.
 Step  11: Agent moved DOWN_LEFT to location [x=1,y=5], based on policy.
 Step  12: Agent moved DOWN_LEFT to location [x=3,y=0], based on policy.

>>> Agent Brain:
 ?  O  O  A  O  D  B  ? 
 B  O  ?  ?  B  O  B  ? 
 R  ?  ?  B  O  ?  ?  ? 
 ?  B  ?  O  ?  B  ?  ? 
 ?  B  O  B  ?  B  ?  ? 
 ?  O  ?  ?  ?  ?  ?  ? 

>>> Best Path: 2.

>>> Process Time: 97.569000 s.
